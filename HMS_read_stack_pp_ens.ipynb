{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9ff672",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import os\n",
    "    new_directory = \"workspace/\"\n",
    "    os.chdir(new_directory)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2472b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config CONFIG]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/root/.local/share/jupyter/runtime/kernel-v2-333k800KYFamajG.json\n",
      "2024-04-18 18:57:33,426 - INFO - logger set up\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Import\n",
    "# =============================\n",
    "#system    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import importlib\n",
    "#the basics\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# ===============\n",
    "# import mycode\n",
    "# ===============\n",
    "sys.path.append(\"./src\")\n",
    "#utils\n",
    "from utils.utils import seed_everything,AttrDict\n",
    "from utils.logger import setup_logger, LOGGER\n",
    "# ===============\n",
    "# Read yaml     \n",
    "# ===============\n",
    "from argparse import ArgumentParser\n",
    "try:\n",
    "    parser       = ArgumentParser()\n",
    "    parser.add_argument('--config', type=str)\n",
    "    args         = parser.parse_args()\n",
    "    config_name  = args.config\n",
    "except:\n",
    "    config_name = None\n",
    "    \n",
    "if config_name==None:\n",
    "    with open('./yaml/config_HMS_read_stack_pp_ens.yaml', 'r') as yml:\n",
    "        config              = yaml.safe_load(yml)\n",
    "else:\n",
    "    with open('./yaml/'+config_name+'.yaml', 'r') as yml:\n",
    "        config             = yaml.safe_load(yml)\n",
    "# ===============\n",
    "# Path_Base     \n",
    "# ===============\n",
    "EXP_ID                  = config['EXP_ID']\n",
    "LOGGER_dir              = config['path']['LOGGER_dir']\n",
    "LOGGER_PATH             = LOGGER_dir+'/log_'+EXP_ID+\".txt\"\n",
    "input_dir               = config['path']['input_dir']\n",
    "data_dir                = config['path']['data_dir']\n",
    "output_dir              = config['path']['output_dir']\n",
    "save_output_dir         = f'{output_dir}/{EXP_ID}'\n",
    "os.makedirs(save_output_dir,exist_ok=True)\n",
    "# ===============\n",
    "# utils\n",
    "# ===============\n",
    "seed                    = config['train']['SEED']\n",
    "seed_everything(seed)\n",
    "# ===============\n",
    "# LOGGER\n",
    "# ===============\n",
    "setup_logger(out_file=LOGGER_PATH)\n",
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#AttrDict\n",
    "config             = AttrDict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b20c37",
   "metadata": {},
   "source": [
    "# Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9756e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting\n",
    "col_labels              = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "col_labels_logits       = [s.split('_')[0]+'_logits' for s in col_labels]\n",
    "select_id               = config['calc_mode']['select_id']\n",
    "select_col_label        = config['calc_mode']['select_col_label']\n",
    "data_type               = config['calc_mode']['data_type']\n",
    "if select_col_label =='proba':\n",
    "    col_labels_feat     = col_labels\n",
    "elif select_col_label =='logits':\n",
    "    col_labels_feat     = col_labels_logits\n",
    "fold_type               = config['calc_mode']['fold_type']\n",
    "if fold_type == 'TH':\n",
    "    if data_type =='ALL':\n",
    "        dir_master      = 'master_FOLD_TH_exp962_ALL'\n",
    "        all_mode        = True\n",
    "    else:\n",
    "        dir_master      = 'master_FOLD_TH_exp963'\n",
    "        all_mode        = False\n",
    "    exp_id_fold         = 'exp_id_fold_TH'\n",
    "elif fold_type == 'THV2':\n",
    "    if data_type =='ALL':\n",
    "        dir_master      = 'master_FOLD_TH_exp970_ALL'\n",
    "        all_mode        = True\n",
    "    else:\n",
    "        dir_master      = 'master_FOLD_THV2_exp971'\n",
    "        all_mode        = False\n",
    "    exp_id_fold         = 'exp_id_fold_THV2'\n",
    "exp_id_spec             = config[exp_id_fold]['spec']\n",
    "exp_id_eeg_wave         = config[exp_id_fold]['eeg_wave']\n",
    "exp_id_eeg_img          = config[exp_id_fold]['eeg_img']\n",
    "exp_id_multi            = config[exp_id_fold]['multi']\n",
    "config['calc_mode']['Calc_Fold'] = config[exp_id_fold]['Calc_Fold']\n",
    "\n",
    "stacking_mode           = config['calc_mode']['stacking_mode']\n",
    "calc_stack              = config['calc_mode']['calc_stack']\n",
    "calc_pp                 = config['calc_mode']['calc_pp']\n",
    "\n",
    "label_mode              = config['calc_mode']['label_mode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6f8ea",
   "metadata": {},
   "source": [
    "# 1_Read_Data_Save  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc41b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 18:57:35,983 - INFO - ==Read exp_id: result_KM_CV_0.2633_oof==\n",
      "2024-04-18 18:57:36,553 - INFO - ==Read exp_id: result_KM_CV_0.2698_oof==\n",
      "2024-04-18 18:57:37,033 - INFO - ==Read exp_id: result_KM_CV_0.2729_oof==\n",
      "2024-04-18 18:57:37,628 - INFO - ==Read exp_id: exp461_EEG_WAVE_multi1D_deep1D_cnn2D_Fold_THv2_HvoteData_pretrain_exp460==\n",
      "2024-04-18 18:57:37,792 - INFO - ==Read exp_id: result_TH_wavenet_maxxvits_downsample_foldV2_oof==\n",
      "2024-04-18 18:57:38,065 - INFO - ==Read exp_id: result_TH_wavenet_effnetb4_downsample_foldV2_oof==\n",
      "2024-04-18 18:57:38,332 - INFO - ==Read exp_id: result_TH_wavenet_maxxvitv2n_downsample_foldV2_oof==\n",
      "2024-04-18 18:57:38,600 - INFO - ==Read exp_id: exp341_SPEC_effb0ns_maxxvit_Fold_THv2_HvoteData_pretrain_exp340==\n",
      "2024-04-18 18:57:38,759 - INFO - ==Read exp_id: exp551_EEG_IMG_stft_512_24_16ch_effb0ns_maxxvit_Fold_THv2_add_aug_HvoteData_pretrain_exp550==\n",
      "2024-04-18 18:57:38,919 - INFO - ==Read exp_id: exp971_MULTI_exp340_460_550_logits_out_Fold_THv2_HvoteData_pretrain_exp970==\n"
     ]
    }
   ],
   "source": [
    "import postprocess.utils_read_stack_pp_ens\n",
    "importlib.reload(postprocess.utils_read_stack_pp_ens)\n",
    "from postprocess.utils_read_stack_pp_ens import read_result,softmax_second_axis\n",
    "\n",
    "#read_master\n",
    "if label_mode == 'specified':\n",
    "    master_label            = pd.read_csv(f'{output_dir}/{dir_master}/df_oof_labels.csv')\n",
    "    master_meta             = pd.read_csv(f'{output_dir}/{dir_master}/train_meta.csv')\n",
    "    master_label            = master_label.drop(columns=['Unnamed: 0','flg2_kl'])\n",
    "    master_label            = master_label.rename(columns={'label_ids':'label_id','eeg_ids':'eeg_id','spectrogram_ids':'spectrogram_id','patient_ids':'patient_id'})\n",
    "    master_label            = master_label.merge(master_meta[['label_id','fold']],on='label_id',how='left')\n",
    "    uni_eeg_id              = list(master_label['eeg_id'].unique())\n",
    "    uni_label_id            = list(master_label['label_id'].unique())\n",
    "    uni_eeg_id.sort()\n",
    "    uni_label_id.sort()\n",
    "    master_label            = master_label.sort_values(by=['patient_id', 'eeg_id'], ascending=[True, True]).reset_index(drop=True)\n",
    "    master_label.to_csv(f'{save_output_dir}/master_label.csv',index=False)\n",
    "    \n",
    "elif label_mode == 'center':\n",
    "    master_label_all        = pd.read_csv(f'{output_dir}/{dir_master}/df_oof_labels_all.csv')\n",
    "    master_meta             = pd.read_csv(f'{output_dir}/{dir_master}/train_meta.csv')\n",
    "    master_label_all        = master_label_all.merge(master_meta[['label_id','flg1_vote']],on='label_id',how='left')\n",
    "    #各eeg_idの中央値を取得する処理\n",
    "    master_label            = master_label_all.groupby('eeg_id').apply(lambda x: x.iloc[len(x) // 2])\n",
    "    master_label            = master_label[master_label['flg1_vote']==True].reset_index(drop=True)\n",
    "    uni_eeg_id              = list(master_label['eeg_id'].unique())\n",
    "    uni_label_id            = list(master_label['label_id'].unique())\n",
    "    uni_eeg_id.sort()\n",
    "    uni_label_id.sort()\n",
    "    master_label            = master_label.sort_values(by=['patient_id', 'eeg_id'], ascending=[True, True]).reset_index(drop=True)\n",
    "    master_label            = master_label[col_labels + \\\n",
    "                                            ['label_id','eeg_id','spectrogram_id','patient_id','flg1_vote','fold']]\n",
    "    master_label.to_csv(f'{save_output_dir}/master_label.csv',index=False)\n",
    "    \n",
    "#read&save_oof\n",
    "exp_ids                     = [exp_id_spec,exp_id_eeg_wave,exp_id_eeg_img,exp_id_multi]\n",
    "for exp_id_type in exp_ids:\n",
    "    for exp_id in exp_id_type:\n",
    "        LOGGER.info(f'==Read exp_id: {exp_id}==')\n",
    "        if ('result_TH' in exp_id)or('result_KM' in exp_id):\n",
    "            load_output_dir = f'{output_dir}/{exp_id}'\n",
    "            df_oof_output   = pd.read_csv(f'{load_output_dir}/df_oof_output.csv')#全label_idデータ\n",
    "            col_select      = ['label_id','eeg_id','spectrogram_id','patient_id','fold',\n",
    "                               'logit_seizure_vote','logit_lpd_vote','logit_gpd_vote','logit_lrda_vote','logit_grda_vote','logit_other_vote',\n",
    "                                ]\n",
    "            df_oof_output   = df_oof_output[col_select]\n",
    "            df_oof_output   = df_oof_output.rename(columns={'logit_seizure_vote':'seizure_logits',\n",
    "                                                            'logit_lpd_vote':'lpd_logits',\n",
    "                                                            'logit_gpd_vote':'gpd_logits',\n",
    "                                                            'logit_lrda_vote':'lrda_logits',\n",
    "                                                            'logit_grda_vote':'grda_logits',\n",
    "                                                            'logit_other_vote':'other_logits',\n",
    "                                                           })\n",
    "            df_oof_output[col_labels]   = softmax_second_axis(df_oof_output[col_labels_logits].values)\n",
    "            df_oof_output               = df_oof_output[df_oof_output['label_id'].isin(uni_label_id)].reset_index(drop=True)\n",
    "        else:\n",
    "            if label_mode == 'specified':\n",
    "                df_oof_output,_,_       = read_result(exp_id,col_labels,output_dir,use_tta=False,print_data=False,all_mode=all_mode)\n",
    "            else:\n",
    "                load_output_dir         = f'{output_dir}/{exp_id}'\n",
    "                df_oof_output_all       = pd.read_csv(f'{load_output_dir}/df_oof_output_all.csv')#全label_idデータ\n",
    "                df_oof_output_all[col_labels]   = softmax_second_axis(df_oof_output_all[col_labels_logits].values)\n",
    "                df_oof_output           = df_oof_output_all[df_oof_output_all['label_id'].isin(uni_label_id)].reset_index(drop=True)\n",
    "        #select\n",
    "        if select_id=='eeg_id':\n",
    "            df_oof_output               = df_oof_output[df_oof_output['eeg_id'].isin(uni_eeg_id)]\n",
    "        elif select_id=='label_id':\n",
    "            df_oof_output               = df_oof_output[df_oof_output['label_id'].isin(uni_label_id)]\n",
    "        df_oof_output = df_oof_output.sort_values(by=['patient_id', 'eeg_id'], ascending=[True, True]).reset_index(drop=True)\n",
    "        #Error\n",
    "        if len(df_oof_output) != len(master_label):\n",
    "            LOGGER.info(f'len(df_oof_output): {len(df_oof_output)}')\n",
    "            LOGGER.info(f'len(master_label): {len(master_label)}')\n",
    "            LOGGER.info('Error')\n",
    "            aa\n",
    "        df_oof_output.to_csv(f'{save_output_dir}/df_oof_{exp_id}.csv',index=False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91960792",
   "metadata": {},
   "source": [
    "# 2_Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee2d288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 18:57:39,672 - INFO - ==Read exp_id: result_KM_CV_0.2633_oof==\n",
      "2024-04-18 18:57:39,687 - INFO - ==Read exp_id: exp461_EEG_WAVE_multi1D_deep1D_cnn2D_Fold_THv2_HvoteData_pretrain_exp460==\n",
      "2024-04-18 18:57:39,716 - INFO - ==Read exp_id: exp341_SPEC_effb0ns_maxxvit_Fold_THv2_HvoteData_pretrain_exp340==\n",
      "2024-04-18 18:57:39,735 - INFO - ==Read exp_id: exp971_MULTI_exp340_460_550_logits_out_Fold_THv2_HvoteData_pretrain_exp970==\n",
      "2024-04-18 18:57:39,768 - INFO - ==Stacking_0: ['result_KM_CV_0.2633_oof', 'exp461_EEG_WAVE_multi1D_deep1D_cnn2D_Fold_THv2_HvoteData_pretrain_exp460', 'exp341_SPEC_effb0ns_maxxvit_Fold_THv2_HvoteData_pretrain_exp340', 'exp971_MULTI_exp340_460_550_logits_out_Fold_THv2_HvoteData_pretrain_exp970']==\n",
      "2024-04-18 18:57:39,769 - INFO - ============Fold:0 Start============\n",
      "2024-04-18 18:57:40,513 - INFO - ===Starting training loop===\n",
      "2024-04-18 18:57:40,516 - INFO - EPOCHS=200\n",
      "2024-04-18 18:57:41,089 - INFO - Ep 0, ==Train END==, Train_Loss: 0.7066\n",
      "2024-04-18 18:57:41,090 - INFO - ======Saving new best model at epoch 0,  Val_Loss: 0.3646, Val_Metrics: 0.3659)======\n",
      "2024-04-18 18:57:41,100 - INFO - ======MAE : ['0.06', '0.10', '0.10', '0.09', '0.08', '0.15']======\n",
      "2024-04-18 18:57:41,101 - INFO - ======ACC : ['0.0', '83.3', '65.6', '0.0', '0.0', '97.5']======\n",
      "2024-04-18 18:57:41,241 - INFO - Ep 1, ==Train END==, Train_Loss: 0.2948\n",
      "2024-04-18 18:57:41,242 - INFO - ======Saving new best model at epoch 1,  Val_Loss: 0.2405, Val_Metrics: 0.2403)======\n",
      "2024-04-18 18:57:41,246 - INFO - ======MAE : ['0.05', '0.07', '0.06', '0.07', '0.06', '0.12']======\n",
      "2024-04-18 18:57:41,247 - INFO - ======ACC : ['0.0', '87.4', '78.5', '4.3', '14.9', '95.6']======\n",
      "2024-04-18 18:57:41,389 - INFO - Ep 2, ==Train END==, Train_Loss: 0.2169\n",
      "2024-04-18 18:57:41,390 - INFO - ======Saving new best model at epoch 2,  Val_Loss: 0.1979, Val_Metrics: 0.1966)======\n",
      "2024-04-18 18:57:41,394 - INFO - ======MAE : ['0.04', '0.06', '0.05', '0.06', '0.05', '0.10']======\n",
      "2024-04-18 18:57:41,395 - INFO - ======ACC : ['21.4', '87.4', '85.3', '28.6', '30.9', '94.5']======\n",
      "2024-04-18 18:57:41,530 - INFO - Ep 3, ==Train END==, Train_Loss: 0.1838\n",
      "2024-04-18 18:57:41,532 - INFO - ======Saving new best model at epoch 3,  Val_Loss: 0.1763, Val_Metrics: 0.1746)======\n",
      "2024-04-18 18:57:41,537 - INFO - ======MAE : ['0.03', '0.06', '0.05', '0.05', '0.05', '0.10']======\n",
      "2024-04-18 18:57:41,537 - INFO - ======ACC : ['40.5', '89.9', '84.0', '37.1', '35.1', '93.3']======\n",
      "2024-04-18 18:57:41,692 - INFO - Ep 4, ==Train END==, Train_Loss: 0.1691\n",
      "2024-04-18 18:57:41,693 - INFO - ======Saving new best model at epoch 4,  Val_Loss: 0.167, Val_Metrics: 0.165)======\n",
      "2024-04-18 18:57:41,698 - INFO - ======MAE : ['0.03', '0.06', '0.05', '0.05', '0.05', '0.10']======\n",
      "2024-04-18 18:57:41,699 - INFO - ======ACC : ['52.4', '88.6', '85.3', '44.3', '37.2', '93.4']======\n",
      "2024-04-18 18:57:41,895 - INFO - Ep 5, ==Train END==, Train_Loss: 0.1644\n",
      "2024-04-18 18:57:41,896 - INFO - ======Saving new best model at epoch 5,  Val_Loss: 0.1625, Val_Metrics: 0.1601)======\n",
      "2024-04-18 18:57:41,902 - INFO - ======MAE : ['0.03', '0.06', '0.04', '0.04', '0.05', '0.09']======\n",
      "2024-04-18 18:57:41,902 - INFO - ======ACC : ['57.1', '90.9', '84.7', '54.3', '45.7', '92.2']======\n",
      "2024-04-18 18:57:42,043 - INFO - Ep 6, ==Train END==, Train_Loss: 0.1615\n",
      "2024-04-18 18:57:42,044 - INFO - ======Saving new best model at epoch 6,  Val_Loss: 0.1588, Val_Metrics: 0.1565)======\n",
      "2024-04-18 18:57:42,049 - INFO - ======MAE : ['0.03', '0.06', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:42,050 - INFO - ======ACC : ['61.9', '88.0', '85.9', '54.3', '45.7', '93.0']======\n",
      "2024-04-18 18:57:42,219 - INFO - Ep 7, ==Train END==, Train_Loss: 0.159\n",
      "2024-04-18 18:57:42,220 - INFO - ======Saving new best model at epoch 7,  Val_Loss: 0.158, Val_Metrics: 0.1557)======\n",
      "2024-04-18 18:57:42,225 - INFO - ======MAE : ['0.03', '0.06', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:42,226 - INFO - ======ACC : ['61.9', '90.2', '86.5', '55.7', '45.7', '92.0']======\n",
      "2024-04-18 18:57:42,362 - INFO - Ep 8, ==Train END==, Train_Loss: 0.1575\n",
      "2024-04-18 18:57:42,363 - INFO - ======Saving new best model at epoch 8,  Val_Loss: 0.1553, Val_Metrics: 0.153)======\n",
      "2024-04-18 18:57:42,368 - INFO - ======MAE : ['0.03', '0.06', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:42,370 - INFO - ======ACC : ['61.9', '88.3', '84.7', '54.3', '46.8', '93.3']======\n",
      "2024-04-18 18:57:42,546 - INFO - Ep 9, ==Train END==, Train_Loss: 0.157\n",
      "2024-04-18 18:57:42,547 - INFO - ======Saving new best model at epoch 9,  Val_Loss: 0.1546, Val_Metrics: 0.1519)======\n",
      "2024-04-18 18:57:42,553 - INFO - ======MAE : ['0.03', '0.06', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:42,554 - INFO - ======ACC : ['61.9', '89.3', '82.2', '54.3', '51.1', '92.5']======\n",
      "2024-04-18 18:57:42,731 - INFO - Ep 10, ==Train END==, Train_Loss: 0.1552\n",
      "2024-04-18 18:57:42,732 - INFO - ======Saving new best model at epoch 10,  Val_Loss: 0.1541, Val_Metrics: 0.1518)======\n",
      "2024-04-18 18:57:42,744 - INFO - ======MAE : ['0.03', '0.06', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:42,745 - INFO - ======ACC : ['61.9', '91.5', '82.2', '55.7', '46.8', '92.4']======\n",
      "2024-04-18 18:57:42,901 - INFO - Ep 11, ==Train END==, Train_Loss: 0.1542\n",
      "2024-04-18 18:57:42,902 - INFO - ======Saving new best model at epoch 11,  Val_Loss: 0.152, Val_Metrics: 0.1496)======\n",
      "2024-04-18 18:57:42,906 - INFO - ======MAE : ['0.03', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:42,907 - INFO - ======ACC : ['61.9', '88.3', '82.8', '55.7', '46.8', '93.3']======\n",
      "2024-04-18 18:57:43,125 - INFO - Ep 12, ==Train END==, Train_Loss: 0.1532\n",
      "2024-04-18 18:57:43,126 - INFO - ======Saving new best model at epoch 12,  Val_Loss: 0.1512, Val_Metrics: 0.1488)======\n",
      "2024-04-18 18:57:43,136 - INFO - ======MAE : ['0.03', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:43,137 - INFO - ======ACC : ['61.9', '88.6', '82.2', '52.9', '46.8', '93.4']======\n",
      "2024-04-18 18:57:43,314 - INFO - Ep 13, ==Train END==, Train_Loss: 0.1527\n",
      "2024-04-18 18:57:43,315 - INFO - ======Saving new best model at epoch 13,  Val_Loss: 0.1505, Val_Metrics: 0.1479)======\n",
      "2024-04-18 18:57:43,320 - INFO - ======MAE : ['0.03', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:43,321 - INFO - ======ACC : ['61.9', '90.9', '81.0', '57.1', '48.9', '92.9']======\n",
      "2024-04-18 18:57:43,588 - INFO - Ep 15, ==Train END==, Train_Loss: 0.1522\n",
      "2024-04-18 18:57:43,589 - INFO - ======Saving new best model at epoch 15,  Val_Loss: 0.1501, Val_Metrics: 0.1475)======\n",
      "2024-04-18 18:57:43,594 - INFO - ======MAE : ['0.03', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:43,595 - INFO - ======ACC : ['61.9', '89.9', '81.6', '57.1', '51.1', '92.6']======\n",
      "2024-04-18 18:57:43,730 - INFO - Ep 16, ==Train END==, Train_Loss: 0.1518\n",
      "2024-04-18 18:57:43,731 - INFO - ======Saving new best model at epoch 16,  Val_Loss: 0.1493, Val_Metrics: 0.1468)======\n",
      "2024-04-18 18:57:43,736 - INFO - ======MAE : ['0.03', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:43,737 - INFO - ======ACC : ['61.9', '90.2', '82.8', '64.3', '48.9', '92.2']======\n",
      "2024-04-18 18:57:43,872 - INFO - Ep 17, ==Train END==, Train_Loss: 0.1519\n",
      "2024-04-18 18:57:43,873 - INFO - ======Saving new best model at epoch 17,  Val_Loss: 0.1486, Val_Metrics: 0.146)======\n",
      "2024-04-18 18:57:43,878 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:43,879 - INFO - ======ACC : ['61.9', '89.6', '82.2', '52.9', '48.9', '92.2']======\n",
      "2024-04-18 18:57:44,018 - INFO - Ep 18, ==Train END==, Train_Loss: 0.1509\n",
      "2024-04-18 18:57:44,019 - INFO - ======Saving new best model at epoch 18,  Val_Loss: 0.1482, Val_Metrics: 0.1456)======\n",
      "2024-04-18 18:57:44,026 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:44,027 - INFO - ======ACC : ['61.9', '89.9', '81.6', '57.1', '47.9', '93.6']======\n",
      "2024-04-18 18:57:44,374 - INFO - Ep 20, ==Train END==, Train_Loss: 0.1508\n",
      "2024-04-18 18:57:44,375 - INFO - ======Saving new best model at epoch 20,  Val_Loss: 0.1475, Val_Metrics: 0.145)======\n",
      "2024-04-18 18:57:44,388 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:44,389 - INFO - ======ACC : ['61.9', '89.3', '83.4', '60.0', '46.8', '92.9']======\n",
      "2024-04-18 18:57:44,528 - INFO - Ep 21, ==Train END==, Train_Loss: 0.1501\n",
      "2024-04-18 18:57:44,529 - INFO - ======Saving new best model at epoch 21,  Val_Loss: 0.1471, Val_Metrics: 0.1443)======\n",
      "2024-04-18 18:57:44,534 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:44,534 - INFO - ======ACC : ['61.9', '88.3', '84.0', '51.4', '54.3', '92.5']======\n",
      "2024-04-18 18:57:44,966 - INFO - Ep 23, ==Train END==, Train_Loss: 0.1498\n",
      "2024-04-18 18:57:44,967 - INFO - ======Saving new best model at epoch 23,  Val_Loss: 0.1466, Val_Metrics: 0.144)======\n",
      "2024-04-18 18:57:44,972 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:44,973 - INFO - ======ACC : ['61.9', '88.6', '82.2', '58.6', '47.9', '93.4']======\n",
      "2024-04-18 18:57:45,425 - INFO - Ep 25, ==Train END==, Train_Loss: 0.15\n",
      "2024-04-18 18:57:45,426 - INFO - ======Saving new best model at epoch 25,  Val_Loss: 0.1464, Val_Metrics: 0.1437)======\n",
      "2024-04-18 18:57:45,431 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:45,432 - INFO - ======ACC : ['61.9', '89.9', '79.1', '51.4', '51.1', '93.0']======\n",
      "2024-04-18 18:57:46,740 - INFO - Ep 30, ==Train END==, Train_Loss: 0.1512\n",
      "2024-04-18 18:57:46,741 - INFO - ======Saving new best model at epoch 30,  Val_Loss: 0.1461, Val_Metrics: 0.1436)======\n",
      "2024-04-18 18:57:46,746 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:46,747 - INFO - ======ACC : ['61.9', '89.0', '82.2', '58.6', '42.6', '93.7']======\n",
      "2024-04-18 18:57:46,937 - INFO - Ep 31, ==Train END==, Train_Loss: 0.1492\n",
      "2024-04-18 18:57:46,938 - INFO - ======Saving new best model at epoch 31,  Val_Loss: 0.1458, Val_Metrics: 0.1432)======\n",
      "2024-04-18 18:57:46,944 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:46,945 - INFO - ======ACC : ['61.9', '88.6', '84.7', '54.3', '45.7', '93.0']======\n",
      "2024-04-18 18:57:47,218 - INFO - Ep 32, ==Train END==, Train_Loss: 0.1497\n",
      "2024-04-18 18:57:47,219 - INFO - ======Saving new best model at epoch 32,  Val_Loss: 0.1456, Val_Metrics: 0.1427)======\n",
      "2024-04-18 18:57:47,228 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:47,229 - INFO - ======ACC : ['61.9', '87.7', '83.4', '60.0', '52.1', '92.8']======\n",
      "2024-04-18 18:57:48,067 - INFO - Ep 35, ==Train END==, Train_Loss: 0.1507\n",
      "2024-04-18 18:57:48,068 - INFO - ======Saving new best model at epoch 35,  Val_Loss: 0.1456, Val_Metrics: 0.1426)======\n",
      "2024-04-18 18:57:48,081 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:48,082 - INFO - ======ACC : ['64.3', '89.9', '82.2', '58.6', '54.3', '92.5']======\n",
      "2024-04-18 18:57:49,455 - INFO - Ep 40, ==Train END==, Train_Loss: 0.1478\n",
      "2024-04-18 18:57:49,456 - INFO - ======Saving new best model at epoch 40,  Val_Loss: 0.1451, Val_Metrics: 0.1421)======\n",
      "2024-04-18 18:57:49,468 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:49,469 - INFO - ======ACC : ['64.3', '89.0', '77.3', '61.4', '55.3', '93.0']======\n",
      "2024-04-18 18:57:49,714 - INFO - Ep 41, ==Train END==, Train_Loss: 0.1481\n",
      "2024-04-18 18:57:49,715 - INFO - ======Saving new best model at epoch 41,  Val_Loss: 0.1449, Val_Metrics: 0.1421)======\n",
      "2024-04-18 18:57:49,724 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:49,725 - INFO - ======ACC : ['61.9', '89.6', '81.6', '57.1', '51.1', '93.2']======\n",
      "2024-04-18 18:57:50,532 - INFO - Ep 44, ==Train END==, Train_Loss: 0.1476\n",
      "2024-04-18 18:57:50,533 - INFO - ======Saving new best model at epoch 44,  Val_Loss: 0.145, Val_Metrics: 0.1418)======\n",
      "2024-04-18 18:57:50,538 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:50,539 - INFO - ======ACC : ['64.3', '88.3', '77.9', '51.4', '56.4', '93.3']======\n",
      "2024-04-18 18:57:51,785 - INFO - Ep 49, ==Train END==, Train_Loss: 0.1474\n",
      "2024-04-18 18:57:51,787 - INFO - ======Saving new best model at epoch 49,  Val_Loss: 0.1446, Val_Metrics: 0.1418)======\n",
      "2024-04-18 18:57:51,800 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:51,800 - INFO - ======ACC : ['64.3', '88.6', '84.7', '61.4', '51.1', '92.6']======\n",
      "2024-04-18 18:57:52,571 - INFO - Ep 54, ==Train END==, Train_Loss: 0.1475\n",
      "2024-04-18 18:57:52,572 - INFO - ======Saving new best model at epoch 54,  Val_Loss: 0.1447, Val_Metrics: 0.1418)======\n",
      "2024-04-18 18:57:52,585 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:52,586 - INFO - ======ACC : ['66.7', '88.6', '81.0', '52.9', '53.2', '93.2']======\n",
      "2024-04-18 18:57:53,572 - INFO - Ep 60, ==Train END==, Train_Loss: 0.147\n",
      "2024-04-18 18:57:53,573 - INFO - ======Saving new best model at epoch 60,  Val_Loss: 0.1447, Val_Metrics: 0.1418)======\n",
      "2024-04-18 18:57:53,577 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:53,578 - INFO - ======ACC : ['61.9', '87.7', '82.2', '52.9', '52.1', '93.7']======\n",
      "2024-04-18 18:57:53,842 - INFO - Ep 62, ==Train END==, Train_Loss: 0.1476\n",
      "2024-04-18 18:57:53,843 - INFO - ======Saving new best model at epoch 62,  Val_Loss: 0.1447, Val_Metrics: 0.1417)======\n",
      "2024-04-18 18:57:53,849 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:53,850 - INFO - ======ACC : ['66.7', '89.0', '84.0', '52.9', '55.3', '93.0']======\n",
      "2024-04-18 18:57:55,031 - INFO - Ep 71, ==Train END==, Train_Loss: 0.1476\n",
      "2024-04-18 18:57:55,033 - INFO - ======Saving new best model at epoch 71,  Val_Loss: 0.1447, Val_Metrics: 0.1416)======\n",
      "2024-04-18 18:57:55,038 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:55,039 - INFO - ======ACC : ['61.9', '88.3', '85.9', '58.6', '55.3', '92.2']======\n",
      "2024-04-18 18:57:55,319 - INFO - Ep 73, ==Train END==, Train_Loss: 0.147\n",
      "2024-04-18 18:57:55,321 - INFO - ======Saving new best model at epoch 73,  Val_Loss: 0.1443, Val_Metrics: 0.1416)======\n",
      "2024-04-18 18:57:55,326 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:55,326 - INFO - ======ACC : ['61.9', '87.4', '82.8', '55.7', '48.9', '93.6']======\n",
      "2024-04-18 18:57:57,250 - INFO - Ep 86, ==Train END==, Train_Loss: 0.1462\n",
      "2024-04-18 18:57:57,251 - INFO - ======Saving new best model at epoch 86,  Val_Loss: 0.1445, Val_Metrics: 0.1414)======\n",
      "2024-04-18 18:57:57,256 - INFO - ======MAE : ['0.02', '0.05', '0.04', '0.04', '0.04', '0.09']======\n",
      "2024-04-18 18:57:57,257 - INFO - ======ACC : ['61.9', '87.1', '83.4', '51.4', '53.2', '93.7']======\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#stacking\u001b[39;00m\n\u001b[1;32m     52\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m==Stacking_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx_stack\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m df_oof_output_stacking,oof_metrics_stacking     \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop_pp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_oof_output_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcol_labels_allfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcol_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43msave_output_dir_stacking_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLOGGER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstacking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m df_oof_output_stacking                          \u001b[38;5;241m=\u001b[39m df_oof_output_stacking\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspectrogram_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspectrogram_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     57\u001b[0m df_oof_output_stacking                          \u001b[38;5;241m=\u001b[39m df_oof_output_stacking\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg_id\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/workspace/./src/trainer/train_pp.py:94\u001b[0m, in \u001b[0;36mtrain_loop_pp\u001b[0;34m(df_feat, col_feat, col_label, config, save_output_dir, LOGGER, mode)\u001b[0m\n\u001b[1;32m     91\u001b[0m scheduler               \u001b[38;5;241m=\u001b[39m get_cosine_schedule_with_warmup(optimizer, num_training_steps\u001b[38;5;241m=\u001b[39mmax_steps,\n\u001b[1;32m     92\u001b[0m                                                             num_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     93\u001b[0m history_fold            \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 94\u001b[0m history_fold            \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_train_pp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_output_dir_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLOGGER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mhistory_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# ===============\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# result_fold\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# =============== \u001b[39;00m\n\u001b[1;32m    102\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m============Fold:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_fold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m END============\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/./src/trainer/train_pp.py:244\u001b[0m, in \u001b[0;36mcalc_train_pp\u001b[0;34m(model, config, train_loader, val_loader, optimizer, scheduler, loss_function, save_output_dir, LOGGER, n_epochs, DEVICE, history_fold)\u001b[0m\n\u001b[1;32m    242\u001b[0m loss                    \u001b[38;5;241m=\u001b[39m loss_function(pred, label)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m#=backpropagation=\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m         \n\u001b[1;32m    245\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()        \n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m#=get_loss_corr_metric_in_batch=\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import trainer.train_pp\n",
    "importlib.reload(trainer.train_pp)\n",
    "from trainer.train_pp import train_loop_pp\n",
    "#dir\n",
    "os.makedirs(f'{save_output_dir}/stacking',exist_ok=True)\n",
    "save_output_dir_stacking        = f'{save_output_dir}/stacking'\n",
    "\n",
    "if calc_stack:\n",
    "    #setting\n",
    "    if stacking_mode=='all_comb':\n",
    "        comb4                   = list(itertools.product(exp_id_spec, exp_id_eeg_wave, exp_id_eeg_img, exp_id_multi))\n",
    "        list_comb4              = [list(comb) for comb in comb4]\n",
    "        comb3                   = list(itertools.product(exp_id_spec, exp_id_eeg_wave, exp_id_eeg_img))\n",
    "        list_comb3              = [list(comb) for comb in comb3]\n",
    "        list_comb               = list_comb4\n",
    "        \n",
    "    elif stacking_mode=='set_comb':\n",
    "        list_comb               = config[exp_id_fold]['set_comb']\n",
    "\n",
    "    #stacking\n",
    "    base_cols                   = ['eeg_id', 'spectrogram_id','patient_id','label_id', 'fold']\n",
    "\n",
    "    id_stacking                 = []\n",
    "    id_comb                     = []\n",
    "    metrics_stacking            = []\n",
    "    for idx_stack,comb in enumerate(list_comb):\n",
    "        os.makedirs(f'{save_output_dir}/stacking/{idx_stack}',exist_ok=True)\n",
    "        save_output_dir_stacking_idx        = f'{save_output_dir}/stacking/{idx_stack}'\n",
    "        id_stacking.append(f'stacking_{idx_stack}')\n",
    "        id_comb.append(comb)\n",
    "        #=get_feat=#\n",
    "        col_labels_allfeat          = []\n",
    "        for idx_exp,exp_id in enumerate(comb):\n",
    "            LOGGER.info(f'==Read exp_id: {exp_id}==')\n",
    "            df_oof_output           = pd.read_csv(f'{save_output_dir}/df_oof_{exp_id}.csv')\n",
    "            df_oof_output           = df_oof_output[base_cols+col_labels_feat]\n",
    "            df_oof_output           = df_oof_output.sort_values(by=['patient_id', 'eeg_id'], ascending=[True, True]).reset_index(drop=True)\n",
    "            #rename\n",
    "            column_mapping          = {col: f\"{col}_{idx_exp}\" for col in col_labels_feat if col in df_oof_output.columns}\n",
    "            new_columns             = list(column_mapping.values())\n",
    "            df_oof_output           = df_oof_output.rename(columns=column_mapping)\n",
    "            col_labels_allfeat      +=new_columns\n",
    "            if idx_exp==0:\n",
    "                df_oof_output_all   = df_oof_output\n",
    "            else:\n",
    "                df_oof_output_all   = df_oof_output_all.merge(df_oof_output[['patient_id','eeg_id']+new_columns],on=['patient_id','eeg_id'],how='left')\n",
    "        #=add_label=#\n",
    "        df_oof_output_all           = df_oof_output_all.merge(master_label[['patient_id','eeg_id']+col_labels],on=['patient_id','eeg_id'],how='left')\n",
    "        \n",
    "        #stacking\n",
    "        LOGGER.info(f'==Stacking_{idx_stack}: {comb}==')\n",
    "        df_oof_output_stacking,oof_metrics_stacking     = train_loop_pp(df_oof_output_all,col_labels_allfeat,col_labels,config,\n",
    "                                                                        save_output_dir_stacking_idx,LOGGER,\n",
    "                                                                        mode='stacking')\n",
    "        df_oof_output_stacking                          = df_oof_output_stacking.rename(columns={'label_ids':'label_id','eeg_ids':'eeg_id','spectrogram_ids':'spectrogram_id','patient_ids':'patient_id'})\n",
    "        df_oof_output_stacking                          = df_oof_output_stacking.sort_values(by=['patient_id', 'eeg_id'], ascending=[True, True]).reset_index(drop=True)\n",
    "        df_oof_output_stacking.to_csv(f'{save_output_dir_stacking}/df_oof_stacking_{idx_stack}.csv',index=False)\n",
    "        metrics_stacking.append(oof_metrics_stacking)\n",
    "    #save_stacking_list\n",
    "    df_stacking                     = pd.DataFrame({'id_stacking':id_stacking,'id_comb':id_comb,'metrics':metrics_stacking})\n",
    "    df_stacking.to_csv(f'{save_output_dir_stacking}/df_stacking.csv',index=False)\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908ff5e",
   "metadata": {},
   "source": [
    "# 3 Ens1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9575c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import postprocess.utils_read_stack_pp_ens\n",
    "importlib.reload(postprocess.utils_read_stack_pp_ens)\n",
    "from postprocess.utils_read_stack_pp_ens import preprocess_ensemble,calc_optuna\n",
    "\n",
    "#dir\n",
    "os.makedirs(f'{save_output_dir}/ens1',exist_ok=True)\n",
    "save_output_dir_ens1    = f'{save_output_dir}/ens1'\n",
    "#setting\n",
    "calc_init               = True\n",
    "\n",
    "#=preprocess_ens1_spec=#\n",
    "weight_init_spec_tmp    = [1]*len(exp_id_spec)\n",
    "model_type_spec         = ['SPEC']*len(exp_id_spec)\n",
    "path_spec               = [f'{save_output_dir}/df_oof_{exp_id}.csv' for exp_id in exp_id_spec]\n",
    "weight_init_spec,oof_data_spec,label_data_spec,criterion_spec,df_oof_spec       = preprocess_ensemble(exp_id_spec,path_spec,col_labels_feat,weight_init_spec_tmp,\n",
    "                                                                                            master_label,col_labels,calc_init=calc_init)\n",
    "\n",
    "#=preprocess_ens1_wave=#\n",
    "weight_init_wave_tmp    = [2]*len(exp_id_eeg_wave)\n",
    "model_type_wave         = ['WAVE']*len(exp_id_eeg_wave)\n",
    "path_wave               = [f'{save_output_dir}/df_oof_{exp_id}.csv' for exp_id in exp_id_eeg_wave]\n",
    "weight_init_wave,oof_data_wave,label_data_wave,criterion_wave,df_oof_wave       = preprocess_ensemble(exp_id_eeg_wave,path_wave,col_labels_feat,weight_init_wave_tmp,\n",
    "                                                                                            master_label,col_labels,calc_init=calc_init)\n",
    "\n",
    "#=preprocess_ens1_img=#\n",
    "weight_init_img_tmp     = [1]*len(exp_id_eeg_img)\n",
    "model_type_img          = ['IMG']*len(exp_id_eeg_img)\n",
    "path_img                = [f'{save_output_dir}/df_oof_{exp_id}.csv' for exp_id in exp_id_eeg_img]\n",
    "weight_init_img,oof_data_img,label_data_img,criterion_img,df_oof_img            = preprocess_ensemble(exp_id_eeg_img,path_img,col_labels_feat,weight_init_img_tmp,\n",
    "                                                                                            master_label,col_labels,calc_init=calc_init)\n",
    "\n",
    "#=preprocess_ens1_multi=#\n",
    "weight_init_multi_tmp   = [4]*len(exp_id_multi)\n",
    "model_type_multi        = ['MULTI']*len(exp_id_multi)\n",
    "path_multi              = [f'{save_output_dir}/df_oof_{exp_id}.csv' for exp_id in exp_id_multi]\n",
    "weight_init_multi,oof_data_multi,label_data_multi,criterion_multi,df_oof_multi  = preprocess_ensemble(exp_id_multi,path_multi,col_labels_feat,weight_init_multi_tmp,\n",
    "                                                                                            master_label,col_labels,calc_init=calc_init)\n",
    "\n",
    "#=preprocess_ens1_stack=#\n",
    "if calc_stack:\n",
    "    exp_id_stack            = df_stacking['id_stacking'].values.tolist()\n",
    "    weight_init_stack_tmp   = [6]*len(exp_id_stack)\n",
    "    model_type_stack        = ['STACK']*len(exp_id_stack)\n",
    "    path_stack              = [f'{save_output_dir_stacking}/df_oof_stacking_{idx_stack}.csv' for idx_stack in range(len(exp_id_stack))]\n",
    "    weight_init_stack,oof_data_stack,label_data_stack,criterion_stack,df_oof_stack  = preprocess_ensemble(exp_id_stack,path_stack,col_labels_feat,weight_init_stack_tmp,\n",
    "                                                                                                master_label,col_labels,calc_init=calc_init)\n",
    "else:\n",
    "    exp_id_stack            = []\n",
    "    weight_init_stack_tmp   = []\n",
    "    model_type_stack        = []\n",
    "    path_stack              = []\n",
    "    weight_init_stack       = []\n",
    "    oof_data_stack          = []\n",
    "    label_data_stack        = []\n",
    "    criterion_stack         = []\n",
    "    df_oof_stack            = []\n",
    "    \n",
    "#=preprocess_ens1_all=#\n",
    "exp_id_ens1_all             = exp_id_spec + exp_id_eeg_wave + exp_id_eeg_img + exp_id_multi \\\n",
    "                              + exp_id_stack\n",
    "weight_init_ens1_all_tmp    = weight_init_spec_tmp + weight_init_wave_tmp + weight_init_img_tmp + weight_init_multi_tmp \\\n",
    "                              + weight_init_stack_tmp\n",
    "model_type_ens1_all         = model_type_spec + model_type_wave + model_type_img + model_type_multi\\\n",
    "                              + model_type_stack\n",
    "path_ens1_all               = path_spec + path_wave + path_img + path_multi \\\n",
    "                              +path_stack\n",
    "weight_init_ens1_all,oof_data_ens1_all,label_data_ens1_all,criterion_ens1_all,df_oof_ens1_all \\\n",
    "                                                                                = preprocess_ensemble(exp_id_ens1_all,path_ens1_all,col_labels_feat,weight_init_ens1_all_tmp,\n",
    "                                                                                            master_label,col_labels,calc_init=calc_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=========OPTUNA=========')\n",
    "#spec\n",
    "print('===spec===')\n",
    "df_ens1_spec,oof_data_ens1_spec_logits,oof_data_ens1_spec_proba         = calc_optuna(exp_id_spec,weight_init_spec,oof_data_spec,\n",
    "                                                                    label_data_spec,criterion_spec,n_trials=config['optuna']['n_trials_spec'])\n",
    "df_ens1_spec['model_type']              = model_type_spec\n",
    "df_oof_ens1_spec                        = df_oof_spec.copy()\n",
    "df_oof_ens1_spec[col_labels_feat]       = oof_data_ens1_spec_logits\n",
    "df_oof_ens1_spec[col_labels]            = oof_data_ens1_spec_proba\n",
    "df_ens1_spec.to_csv(f'{save_output_dir_ens1}/df_ens1_spec.csv',index=False)\n",
    "df_oof_ens1_spec.to_csv(f'{save_output_dir_ens1}/df_oof_spec.csv',index=False)\n",
    "\n",
    "#eeg_wave\n",
    "print('===eeg_wave===')\n",
    "df_ens1_wave,oof_data_ens1_wave_logits,oof_data_ens1_wave_proba         = calc_optuna(exp_id_eeg_wave,weight_init_wave,oof_data_wave,\n",
    "                                                                    label_data_wave,criterion_wave,n_trials=config['optuna']['n_trials_wave'])\n",
    "df_ens1_wave['model_type']              = model_type_wave\n",
    "df_oof_ens1_wave                        = df_oof_wave.copy()\n",
    "df_oof_ens1_wave[col_labels_feat]       = oof_data_ens1_wave_logits\n",
    "df_oof_ens1_wave[col_labels]            = oof_data_ens1_wave_proba\n",
    "df_ens1_wave.to_csv(f'{save_output_dir_ens1}/df_ens1_wave.csv',index=False)\n",
    "df_oof_ens1_wave.to_csv(f'{save_output_dir_ens1}/df_oof_wave.csv',index=False)\n",
    "\n",
    "#eeg_img\n",
    "print('===eeg_img===')\n",
    "df_ens1_img,oof_data_ens1_img_logits,oof_data_ens1_img_proba           = calc_optuna(exp_id_eeg_img,weight_init_img,oof_data_img,\n",
    "                                                                    label_data_img,criterion_img,n_trials=config['optuna']['n_trials_img'])\n",
    "df_ens1_img['model_type']               = model_type_img\n",
    "df_oof_ens1_img                         = df_oof_img.copy()\n",
    "df_oof_ens1_img[col_labels_feat]        = oof_data_ens1_img_logits\n",
    "df_oof_ens1_img[col_labels]             = oof_data_ens1_img_proba\n",
    "df_ens1_img.to_csv(f'{save_output_dir_ens1}/df_ens1_img.csv',index=False)\n",
    "df_oof_ens1_img.to_csv(f'{save_output_dir_ens1}/df_oof_img.csv',index=False)\n",
    "\n",
    "#multi\n",
    "print('===multi===')\n",
    "df_ens1_multi,oof_data_ens1_multi_logits,oof_data_ens1_multi_proba       = calc_optuna(exp_id_multi,weight_init_multi,oof_data_multi,\n",
    "                                                                    label_data_multi,criterion_multi,n_trials=config['optuna']['n_trials_multi'])\n",
    "df_ens1_multi['model_type']             = model_type_multi\n",
    "df_oof_ens1_multi                       = df_oof_multi.copy()\n",
    "df_oof_ens1_multi[col_labels_feat]      = oof_data_ens1_multi_logits\n",
    "df_oof_ens1_multi[col_labels]           = oof_data_ens1_multi_proba\n",
    "df_ens1_multi.to_csv(f'{save_output_dir_ens1}/df_ens1_multi.csv',index=False)\n",
    "df_oof_ens1_multi.to_csv(f'{save_output_dir_ens1}/df_oof_multi.csv',index=False)\n",
    "\n",
    "#stack\n",
    "if calc_stack:\n",
    "    print('===stack===')\n",
    "    df_ens1_stack,oof_data_ens1_stack_logits,oof_data_ens1_stack_proba       = calc_optuna(exp_id_stack,weight_init_stack,oof_data_stack,\n",
    "                                                                        label_data_stack,criterion_stack,n_trials=config['optuna']['n_trials_stack'])\n",
    "    df_ens1_stack['model_type']             = model_type_stack\n",
    "    df_oof_ens1_stack                       = df_oof_stack.copy()\n",
    "    df_oof_ens1_stack[col_labels_feat]      = oof_data_ens1_stack_logits\n",
    "    df_oof_ens1_stack[col_labels]           = oof_data_ens1_stack_proba\n",
    "    df_ens1_stack.to_csv(f'{save_output_dir_ens1}/df_ens1_stack.csv',index=False)\n",
    "    df_oof_ens1_stack.to_csv(f'{save_output_dir_ens1}/df_oof_stack.csv',index=False)\n",
    "else:\n",
    "    pass\n",
    "#all\n",
    "print('===all===')\n",
    "df_ens1_all,oof_data_ens1_all_logits,oof_data_ens1_all_proba           = calc_optuna(exp_id_ens1_all,weight_init_ens1_all,oof_data_ens1_all,\n",
    "                                                                    label_data_ens1_all,criterion_ens1_all,n_trials=config['optuna']['n_trials_ens1'])\n",
    "df_ens1_all['model_type']               = model_type_ens1_all\n",
    "df_oof_ens1_all[col_labels_feat]        = oof_data_ens1_all_logits\n",
    "df_oof_ens1_all[col_labels]             = oof_data_ens1_all_proba\n",
    "df_ens1_all.to_csv(f'{save_output_dir_ens1}/df_ens1_all.csv',index=False)\n",
    "df_oof_ens1_all.to_csv(f'{save_output_dir_ens1}/df_oof_ens1_all.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69df67",
   "metadata": {},
   "source": [
    "# 4_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainer.train_pp\n",
    "importlib.reload(trainer.train_pp)\n",
    "from trainer.train_pp import preprocess_pp\n",
    "\n",
    "if calc_pp:\n",
    "    #dir\n",
    "    os.makedirs(f'{save_output_dir}/pp',exist_ok=True)\n",
    "    save_output_dir_pp              = f'{save_output_dir}/pp'\n",
    "\n",
    "    #get_feat\n",
    "    dict_df_oof_ens1                = {}\n",
    "    dict_df_oof_ens1['spec']        = df_oof_ens1_spec\n",
    "    dict_df_oof_ens1['wave']        = df_oof_ens1_wave\n",
    "    dict_df_oof_ens1['img']         = df_oof_ens1_img\n",
    "    dict_df_oof_ens1['multi']       = df_oof_ens1_multi\n",
    "    dict_df_oof_ens1['stack']       = df_oof_ens1_stack\n",
    "    dict_df_oof_ens1['ens']         = df_oof_ens1_all\n",
    "\n",
    "    #settings\n",
    "    id_pp                           = []\n",
    "    id_setting_pp                   = []\n",
    "    metrics_pp                      = []\n",
    "    num_set_pp                      = config[exp_id_fold]['set_pp']['num_set']\n",
    "    for idx_pp in range(num_set_pp):\n",
    "        os.makedirs(f'{save_output_dir}/pp/{idx_pp}',exist_ok=True)\n",
    "        save_output_dir_pp_idx        = f'{save_output_dir}/pp/{idx_pp}'\n",
    "        setting_pp                  = config[exp_id_fold]['set_pp'][f'set{idx_pp}']\n",
    "        id_pp.append(f'pp_{idx_pp}')\n",
    "        id_setting_pp.append(setting_pp)\n",
    "\n",
    "        df_feat,new_col_labels_all              = preprocess_pp(dict_df_oof_ens1,setting_pp,col_labels_feat,\n",
    "                                                    master_label,col_labels,)\n",
    "        \n",
    "        LOGGER.info(f'==PP_{idx_pp}==')\n",
    "        LOGGER.info(f'==NUM_FEAT_{idx_pp}: {len(new_col_labels_all)}==')\n",
    "        df_oof_output_pp,oof_metrics_pp         = train_loop_pp(df_feat,new_col_labels_all ,col_labels,config,\n",
    "                                                        save_output_dir_pp_idx,LOGGER,\n",
    "                                                        mode='pp')\n",
    "        df_oof_output_pp                        = df_oof_output_pp.rename(columns={'label_ids':'label_id','eeg_ids':'eeg_id','spectrogram_ids':'spectrogram_id','patient_ids':'patient_id'})\n",
    "        df_oof_output_pp                        = df_oof_output_pp.sort_values(by=['patient_id', 'eeg_id'], ascending=[True, True]).reset_index(drop=True)\n",
    "        df_oof_output_pp.to_csv(f'{save_output_dir_pp}/df_oof_pp_{idx_pp}.csv',index=False)\n",
    "        metrics_pp.append(oof_metrics_pp)\n",
    "\n",
    "    #save_pp_list\n",
    "    df_pp                           = pd.DataFrame({'id_pp':id_pp,'id_setting_pp':id_setting_pp,'metrics':metrics_pp})\n",
    "    df_pp.to_csv(f'{save_output_dir_pp}/df_pp.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb969ba1",
   "metadata": {},
   "source": [
    "# 5 Ens2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef05167",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_pp:\n",
    "    import postprocess.utils_read_stack_pp_ens\n",
    "    importlib.reload(postprocess.utils_read_stack_pp_ens)\n",
    "    from postprocess.utils_read_stack_pp_ens import preprocess_ensemble,calc_optuna\n",
    "\n",
    "    #dir\n",
    "    os.makedirs(f'{save_output_dir}/ens2',exist_ok=True)\n",
    "    save_output_dir_ens2    = f'{save_output_dir}/ens2'\n",
    "\n",
    "    #setting\n",
    "    calc_init               = True\n",
    "\n",
    "    #=preprocess_ens2_spec=#\n",
    "    weight_init_spec_tmp    = [1]*len(exp_id_spec)\n",
    "    model_type_spec         = ['SPEC']*len(exp_id_spec)\n",
    "    path_spec               = [f'{save_output_dir}/df_oof_{exp_id}.csv' for exp_id in exp_id_spec]\n",
    "\n",
    "    #=preprocess_ens2_wave=#\n",
    "    weight_init_wave_tmp    = [2]*len(exp_id_eeg_wave)\n",
    "    model_type_wave         = ['WAVE']*len(exp_id_eeg_wave)\n",
    "    path_wave               = [f'{save_output_dir}/df_oof_{exp_id}.csv' for exp_id in exp_id_eeg_wave]\n",
    "\n",
    "    #=preprocess_ens2_img=#\n",
    "    weight_init_img_tmp     = [1]*len(exp_id_eeg_img)\n",
    "    model_type_img          = ['IMG']*len(exp_id_eeg_img)\n",
    "    path_img                = [f'{save_output_dir}/df_oof_{exp_id}.csv' for exp_id in exp_id_eeg_img]\n",
    "\n",
    "    #=preprocess_ens2_multi=#\n",
    "    weight_init_multi_tmp   = [4]*len(exp_id_multi)\n",
    "    model_type_multi        = ['MULTI']*len(exp_id_multi)\n",
    "    path_multi              = [f'{save_output_dir}/df_oof_{exp_id}.csv' for exp_id in exp_id_multi]\n",
    "\n",
    "    #=preprocess_ens2_stack=#\n",
    "    exp_id_stack            = df_stacking['id_stacking'].values.tolist()\n",
    "    weight_init_stack_tmp   = [6]*len(exp_id_stack)\n",
    "    model_type_stack        = ['STACK']*len(exp_id_stack)\n",
    "    path_stack              = [f'{save_output_dir_stacking}/df_oof_stacking_{idx_stack}.csv' for idx_stack in range(len(exp_id_stack))]\n",
    "\n",
    "    #=preprocess_ens2_pp=#\n",
    "    exp_id_pp               = df_pp['id_pp'].values.tolist()\n",
    "    weight_init_pp_tmp      = [20]*len(exp_id_pp)\n",
    "    model_type_pp           = ['PP']*len(exp_id_pp)\n",
    "    path_pp                 = [f'{save_output_dir_pp}/df_oof_pp_{idx_pp}.csv' for idx_pp in range(len(exp_id_pp))]\n",
    "\n",
    "    #=preprocess_ens2_all=#\n",
    "    exp_id_ens2_all             = exp_id_spec + exp_id_eeg_wave + exp_id_eeg_img + exp_id_multi \\\n",
    "                                + exp_id_stack + exp_id_pp\n",
    "    weight_init_ens2_all_tmp    = weight_init_spec_tmp + weight_init_wave_tmp + weight_init_img_tmp + weight_init_multi_tmp \\\n",
    "                                + weight_init_stack_tmp + weight_init_pp_tmp\n",
    "    model_type_ens2_all         = model_type_spec + model_type_wave + model_type_img + model_type_multi\\\n",
    "                                + model_type_stack + model_type_pp\n",
    "    path_ens2_all               = path_spec + path_wave + path_img + path_multi \\\n",
    "                                +path_stack + path_pp\n",
    "\n",
    "    weight_init_ens2_all,oof_data_ens2_all,label_data_ens2_all,criterion_ens2_all,df_oof_ens2_all \\\n",
    "                                                                                    = preprocess_ensemble(exp_id_ens2_all,path_ens2_all,col_labels_feat,weight_init_ens2_all_tmp,\n",
    "                                                                                                master_label,col_labels,calc_init=calc_init)\n",
    "\n",
    "\n",
    "    print('=========OPTUNA=========')\n",
    "    print('===all===')\n",
    "    df_ens2_all,oof_data_ens2_all_logits,oof_data_ens2_all      = calc_optuna(exp_id_ens2_all,weight_init_ens2_all,oof_data_ens2_all,\n",
    "                                                                    label_data_ens2_all,criterion_ens2_all,n_trials=config['optuna']['n_trials_ens2'])\n",
    "    df_ens2_all['model_type']               = model_type_ens2_all\n",
    "    df_oof_ens2_all[col_labels_feat]        = oof_data_ens2_all_logits\n",
    "    df_oof_ens2_all[col_labels]             = oof_data_ens2_all\n",
    "    df_ens2_all.to_csv(f'{save_output_dir_ens2}/df_ens2_all.csv',index=False)\n",
    "    df_oof_ens2_all.to_csv(f'{save_output_dir_ens2}/df_oof_ens2_all.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2cddce24a8fc711558e66d9211b62795b81cc4d411009a21a45a14e447841c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
